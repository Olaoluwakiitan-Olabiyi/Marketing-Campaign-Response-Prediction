# Marketing-Campaign-Response-Prediction

![Heatmap](https://user-images.githubusercontent.com/71575857/222189504-e4381922-4564-491e-a236-dea0a847572a.png)


<strong>Background</strong>

Sapa.com is one of the leading eCommerce platforms in Nigeria with millions of daily complete transactions. The goods and services on sapa.com cater for both the elite and the masses which makes it the first choice for almost everybody in Nigeria. Due to the COVID-19 pandemic that struck the entire world in all areas of living, the companies' daily complete transactions have dropped drastically to thousands.

The CEO, Mr Echoke in his recent actions to put the platform back to the top of the eCommerce platforms chain in the country has approved the use of Artificial intelligence in User Personality Analysis. The company has contracted your team consisting of AI professionals with a special focus on recommender system development to build a robust intelligent model capable of recommending products and services to Users based on their activities on sapa.com.


<strong>Aim:</strong> 
The purpose of this project is to the build a model capable of predicting users’ responses to marketing campaigns based on the features in the provided dataset by the sapa.com data engineer.
<strong>Application Used: </strong>
Python Language

<strong>About the datasets:</strong>
The dataset used for this project is a fashion retail dataset from 365 Datascience. It has a total of 27 columns and 1568 rows. Data Source: Kaggle >>> https://www.kaggle.com/datasets/rodsaldanha/arketing-campaign

<strong>Methodology:</strong>
- Data cleaning
- Feature selection
- Upsampling
- Feature engineering
- Normalization 
- Encoding

<strong>Classification Algorithim:</strong> 
For the clustering, I had created two groups of features ;

- Logistic Regression
- Decision Trees
- Catboost 
- Naivemodel
- Random Forest
- XgBoost

<strong>Model Evaluation:</strong>
- F1 Score
- Accuracy Score
- Confusion Matrix

<strong>Results:</strong>

Random Forest and XgBoost performed best with an F1 score of 0.98 and 0.91 respectively.

<strong>Furtherwork: </strong>

Overfitting to check for bias and “generalization error" error.
 

